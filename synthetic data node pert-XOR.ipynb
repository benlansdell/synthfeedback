{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "from data_loader.data_generator import MNISTDataGenerator, LinearDataGenerator\n",
    "from models.npmodels import NPModel4,DirectNPModel4,AENPModel,AEDFANPModel\n",
    "from trainers.sf_trainer import SFTrainer, AESFTrainer\n",
    "from utils.config import process_config\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import operator\n",
    "from utils.utils import tf_matmul_r, tf_matmul_l, tf_eigvecs, tf_eigvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,2,size=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inshape=30\n",
    "# hidden=20\n",
    "# outshape=10\n",
    "# batch_size=50\n",
    "# T = rng.randn(outshape, inshape)\n",
    "def traindata(batch_size):\n",
    "    train_x=np.zeros((batch_size,2))\n",
    "    train_y=np.zeros((batch_size))\n",
    "    for i in range(batch_size):\n",
    "        inp=np.random.randint(0,2,size=[1,2])\n",
    "        output=operator.xor(inp[0,0],inp[0,1])\n",
    "        train_x[i,:]=inp\n",
    "        train_y[i]=output\n",
    "    return (train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=50\n",
    "\n",
    "x,y=traindata(10)\n",
    "x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 0., 1., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#p = self.config.state_size[0]\n",
    "p=2# inshape \n",
    "m =10# hiddenshap\n",
    "j = 1#outshpae\n",
    "#n = 10\n",
    "var_xi = 0.1\n",
    "learning_rate=0\n",
    "lmda_learning_rate=1e-5\n",
    "#lmda_learning_rate=0\n",
    "\n",
    "#Training data inputs\n",
    "x=tf.placeholder(tf.float32,[None,p], name = 'x')\n",
    "y=tf.placeholder(tf.float32,[None,j], name = 'y')\n",
    "\n",
    "#Scale weight initialization\n",
    "alpha0 = np.sqrt(2.0/p)\n",
    "alpha1 = np.sqrt(2.0/m)\n",
    "alpha2 = np.sqrt(2.0/j)\n",
    "alpha3 = 1\n",
    "\n",
    "A = tf.Variable(rng.randn(p+1,m)*alpha0, name=\"hidden_weights\", dtype=tf.float32)\n",
    "W = tf.Variable(rng.randn(m+1,j)*alpha1, name=\"output_weights\", dtype=tf.float32)\n",
    "B = tf.Variable(rng.randn(m+1,j)*alpha2, name=\"feedback_weights\", dtype=tf.float32)\n",
    "\n",
    "# network architecture with ones added for bias terms\n",
    "e0 = tf.ones([batch_size, 1], tf.float32)\n",
    "e1 = tf.ones([batch_size, 1], tf.float32)\n",
    "# e0 = tf.ones([1,batch_size], tf.float32)\n",
    "# e1 = tf.ones([1,batch_size], tf.float32)\n",
    "\n",
    "x_aug = tf.concat([x, e0], 1)\n",
    "h = tf.sigmoid(tf.matmul(x_aug, A))\n",
    "#Make some noise\n",
    "h_aug = tf.concat([h, e1], 1)\n",
    "xi = tf.random_normal(shape=tf.shape(h_aug), mean=0.0, stddev=var_xi, dtype=tf.float32)\n",
    "h_tilde = h_aug + xi\n",
    "#Add noise to hidden layer\n",
    "y_p = tf.matmul(h_tilde, W)\n",
    "y_p_0 = tf.matmul(h_aug, W)\n",
    "\n",
    "trainable = [A, W, B]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mean squared error\n",
    "loss = tf.reduce_sum(tf.pow(y_p-y, 2))/2\n",
    "loss_0 = tf.reduce_sum(tf.pow(y_p_0-y, 2))/2\n",
    "e = (y_p - y)\n",
    "h_prime = tf.multiply(h_tilde, 1-h_tilde)[:,0:m]\n",
    "\n",
    "#Feedback data for saving\n",
    "#Only take first item in epoch\n",
    "delta_bp = tf.matmul(e, tf.transpose(W[0:m,:]))[0,:]\n",
    "delta_fa = tf.matmul(e, tf.transpose(B[0:m,:]))[0,:]\n",
    "norm_W = tf.norm(W)\n",
    "norm_B = tf.norm(B)\n",
    "error_FA = tf.norm(delta_bp - delta_fa)\n",
    "alignment = tf.reduce_sum(tf.multiply(delta_fa,delta_bp))/tf.norm(delta_fa)/tf.norm(delta_bp)\n",
    "norm_diff = tf.norm(W - B)\n",
    "eigs = tf_eigvals(tf.matmul(tf.transpose(B), W))\n",
    "\n",
    "#Compute updates for W and A (based on B)\n",
    "lmda = tf.matmul(e, tf.transpose(B[0:m,:]))\n",
    "grad_W = tf.gradients(xs=W, ys=loss)[0]\n",
    "grad_A = tf.matmul(tf.transpose(x_aug), tf.multiply(h_prime, lmda))\n",
    "grad_B = tf.matmul(tf.matmul(B, tf.transpose(e)) - tf.transpose(xi)*(loss - loss_0)/var_xi, e)\n",
    "\n",
    "new_W = W.assign(W - learning_rate*grad_W)\n",
    "new_A = A.assign(A - learning_rate*grad_A)            \n",
    "new_B = B.assign(B - lmda_learning_rate\n",
    "                 *grad_B)            \n",
    "train_step = [new_W, new_A, new_B]\n",
    "correct_prediction = tf.equal(tf.argmax(y_p, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#Also need to add eigenvector stuff\n",
    "training_metrics = [alignment, norm_W, norm_B, error_FA, eigs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "store_al=[]\n",
    "store_df=[]\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "    for idx in range(2000):\n",
    "        (train_x, train_y) = traindata(batch_size)\n",
    "        train_x=np.float32(train_x)\n",
    "        train_y=(np.float32(train_y))\n",
    "        train_y=train_y.reshape((batch_size,1))#to make it [50,1] instead of [50,]\n",
    "#         print(sess.run([alignment],feed_dict={x: train_x, y: train_y}))\n",
    "        _,align,diff=sess.run([train_step,alignment,norm_diff],feed_dict={x: train_x, y: train_y})\n",
    "\n",
    "        store_al.append(align)\n",
    "#         store_df.append(diff)\n",
    "        #print(align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.reshape(batch_size,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=np.random.randint(0,2,size=[1,2])\n",
    "print(t)\n",
    "t[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans=np.zeros((1,1))\n",
    "ans[0]=operator.xor(t[0,0],t[0,1])\n",
    "print(ans)\n",
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r=np.zeros((1,1))\n",
    "r[0]=5\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(store_al)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(store_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py34]",
   "language": "python",
   "name": "conda-env-py34-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
